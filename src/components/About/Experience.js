import React, { useState } from "react";
import { useLanguage } from "../../context/LanguageContext";
import { FaBriefcase, FaGithub } from "react-icons/fa";
import { MdDateRange, MdLocationOn } from "react-icons/md";
import ProjectModal from "./ProjectModal";

function Experience() {
  const { language } = useLanguage();
  const [selectedProject, setSelectedProject] = useState(null);

  const experiences = [
    {
      id: "siemens",
      role: {
        fr: "Ing√©nieur R&D IA en Alternance",
        en: "AI R&D Engineer Apprentice",
      },
      company: "Siemens DISW",
      location: "Lyon, France",
      period: {
        fr: "Octobre 2025 - Octobre 2027 (2 ans)",
        en: "October 2025 - October 2027 (2 years)",
      },
      description: {
        fr: "D√©veloppement de solutions d'intelligence artificielle pour des applications industrielles. Travail sur des architectures d'agents intelligents, NLP, et Computer Vision.",
        en: "Development of artificial intelligence solutions for industrial applications. Working on intelligent agent architectures, NLP, and Computer Vision.",
      },
      technologies: [
        "LangChain",
        "LangGraph",
        "PyTorch",
        "TensorFlow",
        "Docker",
        "REST APIs",
        "SQL",
        "Cypher",
        "Jira",
        "Confluence",
      ],
      current: true,
    },
    {
      id: "libiub",
      role: {
        fr: "Stagiaire en Recherche IA & Vision par Ordinateur",
        en: "Research Intern in AI & Computer Vision",
      },
      company: {
        fr: "Laboratoire d'Informatique de l'Universit√© de Bourgogne (LE2I)",
        en: "Computer Science Laboratory - University of Burgundy (LE2I)",
      },
      location: "Dijon, France",
      period: {
        fr: "Juin 2025 - Ao√ªt 2025 (3 mois)",
        en: "June 2025 - August 2025 (3 months)",
      },
      description: {
        fr: "Stage de recherche ax√© sur la segmentation s√©mantique de nuages de points 3D. D√©veloppement et comparaison de deux architectures de deep learning (PointNet et KPConv) pour la classification d'objets urbains et d'√©l√©ments architecturaux. Travail complet incluant la pr√©paration de datasets, l'entra√Ænement de mod√®les, et l'analyse de r√©sultats.",
        en: "Research internship focused on semantic segmentation of 3D point clouds. Development and comparison of two deep learning architectures (PointNet and KPConv) for urban object and architectural element classification. Complete workflow including dataset preparation, model training, and results analysis.",
      },
      projects: [
        {
          name: {
            fr: "Segmentation Urbaine avec PointNet",
            en: "Urban Segmentation with PointNet",
          },
          description: {
            fr: "Classification de nuages de points 3D du dataset Paris-Lille-3D pour identifier infrastructures urbaines, v√©hicules, pi√©tons et v√©g√©tation",
            en: "Classification of 3D point clouds from Paris-Lille-3D dataset to identify urban infrastructure, vehicles, pedestrians and vegetation",
          },
          detailedDescription: {
            fr: "Projet de segmentation s√©mantique d'environnements urbains √† partir du dataset Paris-Lille-3D. L'objectif √©tait d'entra√Æner un mod√®le PointNet capable de classifier chaque point d'un nuage de points 3D selon sa cat√©gorie s√©mantique (infrastructure, v√©hicules, pi√©tons, v√©g√©tation, mobilier urbain, etc.). Le projet a n√©cessit√© une phase importante de pr√©paration des donn√©es, incluant l'extraction d'objets annot√©s depuis les fichiers PLY, le r√©√©chantillonnage √† 1024 points par objet, et la normalisation. Face aux d√©fis de d√©s√©quilibre de classes et de donn√©es insuffisantes, une approche alternative de subdivision spatiale en blocs de 10m√ó10m a √©t√© d√©velopp√©e pour cr√©er un dataset d'entra√Ænement viable.",
            en: "Semantic segmentation project of urban environments from the Paris-Lille-3D dataset. The goal was to train a PointNet model capable of classifying each point of a 3D point cloud according to its semantic category (infrastructure, vehicles, pedestrians, vegetation, street furniture, etc.). The project required an extensive data preparation phase, including extraction of annotated objects from PLY files, resampling to 1024 points per object, and normalization. Facing challenges of class imbalance and insufficient data, an alternative approach of spatial subdivision into 10m√ó10m blocks was developed to create a viable training dataset.",
          },
          features: [
            {
              fr: "üìä Pr√©paration dataset Paris-Lille-3D : Extraction d'objets depuis fichiers PLY avec plyfile, parsing des annotations avec pandas, mapping des class_id avec classes.xml",
              en: "üìä Paris-Lille-3D dataset preparation: Object extraction from PLY files with plyfile, annotation parsing with pandas, class_id mapping with classes.xml",
            },
            {
              fr: "üîÑ R√©√©chantillonnage adaptatif : Sous-√©chantillonnage al√©atoire si >1024 points, sur-√©chantillonnage par duplication si <1024 points, normalisation centr√©e dans cube unit√©",
              en: "üîÑ Adaptive resampling: Random subsampling if >1024 points, oversampling by duplication if <1024 points, centered normalization in unit cube",
            },
            {
              fr: "üèóÔ∏è Architecture PointNet : MLP successifs (64‚Üí128‚Üí1024), MaxPooling global pour invariance, T√™te de segmentation avec features globales inject√©es",
              en: "üèóÔ∏è PointNet architecture: Successive MLPs (64‚Üí128‚Üí1024), Global MaxPooling for invariance, Segmentation head with injected global features",
            },
            {
              fr: "üì¶ Subdivision spatiale : D√©coupage sc√®nes compl√®tes en blocs 10m√ó10m, Reconstruction de sc√®nes urbaines depuis fichiers d'objets NPY, Alternative au manque de donn√©es objets individuels",
              en: "üì¶ Spatial subdivision: Cutting complete scenes into 10m√ó10m blocks, Reconstruction of urban scenes from NPY object files, Alternative to lack of individual object data",
            },
            {
              fr: "‚öñÔ∏è Gestion d√©s√©quilibre extr√™me : Distribution typique LiDAR (sol 60-70%, autres <10% chacun), Weighted CrossEntropyLoss avec poids inversement proportionnels, Tentatives d'√©quilibrage par √©poque",
              en: "‚öñÔ∏è Extreme imbalance handling: Typical LiDAR distribution (ground 60-70%, others <10% each), Weighted CrossEntropyLoss with inversely proportional weights, Balancing attempts per epoch",
            },
            {
              fr: "üîß Environnement technique : Anaconda (env 'ia') avec PyTorch, numpy, pandas, h5py, plyfile, GPU GTX 1660 Ti utilis√© avec CUDA",
              en: "üîß Technical environment: Anaconda (env 'ia') with PyTorch, numpy, pandas, h5py, plyfile, GTX 1660 Ti GPU used with CUDA",
            },
          ],
          technologies: [
            "Python",
            "PyTorch",
            "PointNet",
            "NumPy",
            "Pandas",
            "Plyfile",
            "H5py",
            "Open3D",
            "Matplotlib",
            "CUDA",
          ],
          results: {
            fr: "üéØ R√©sultats finaux : Meilleure accuracy de 89% atteinte sur dataset de blocs (Paris + Lille), mais probl√®mes persistants de d√©s√©quilibre (classe majoritaire √©crase les pr√©dictions). Distribution finale obtenue : infrastructure (9 objets), other (36), parked_vehicles (36), pedestrian (63), signage (8), street_furniture (40), terrain (1), vegetation (35). Le√ßons apprises : PointNet n√©cessite √©quilibre strict entre classes, nombre minimum d'objets par classe (>30), donn√©es en blocs plus efficaces que objets individuels pour sc√®nes urbaines. Contraintes mat√©rielles : entra√Ænement limit√© par GPU (pas de CPU viable), temps d'entra√Ænement significatif (300+ √©poques n√©cessaires).",
            en: "üéØ Final results: Best accuracy of 89% achieved on block dataset (Paris + Lille), but persistent imbalance issues (majority class crushes predictions). Final distribution obtained: infrastructure (9 objects), other (36), parked_vehicles (36), pedestrian (63), signage (8), street_furniture (40), terrain (1), vegetation (35). Lessons learned: PointNet requires strict class balance, minimum number of objects per class (>30), block data more effective than individual objects for urban scenes. Hardware constraints: training limited by GPU (no viable CPU), significant training time (300+ epochs needed).",
          },
          keyLearnings: {
            fr: [
              {
                title: "üèõÔ∏è Architecture PointNet pour segmentation",
                content: "PointNet traite des nuages de points non ordonn√©s via des MLP partag√©s sur chaque point (64‚Üí128‚Üí1024 canaux). MaxPooling global capture les features globales invariantes aux permutations. Ces features sont ensuite concat√©n√©es avec les features locales de chaque point pour la pr√©diction finale. L'architecture n√©cessite exactement 1024 points par √©chantillon en entr√©e, d'o√π l'importance du r√©√©chantillonnage."
              },
              {
                title: "üì¶ D√©fis de la pr√©paration des donn√©es urbaines",
                content: "Dataset Paris-Lille-3D : fichiers PLY contiennent coordonn√©es XYZ + intensit√© + label + class. Fichier annotation.txt d√©crit les objets segment√©s manuellement. Probl√®me majeur : distribution extr√™mement d√©s√©quilibr√©e (seulement 3 tabourets dans petite ville = sous-apprentissage impossible). Solution finale : subdivision spatiale en blocs de 10m√ó10m couvrant toute la hauteur Z, permettant de cr√©er plus d'√©chantillons d'entra√Ænement."
              },
              {
                title: "‚ö†Ô∏è Probl√©matique du d√©s√©quilibre LiDAR",
                content: "Distribution typique dans dataset LiDAR urbain : Sol (route + trottoir) = 60-70% des points, B√¢timents = 15-20%, V√©hicules = 5-10%, Objets urbains = 2-5%, V√©g√©tation = 3-8%. Ce d√©s√©quilibre √©crasant fait que le mod√®le pr√©dit majoritairement la classe dominante m√™me apr√®s √©quilibrage. R√©sultat typique : 97.8% des points pr√©dits en classe 9, malgr√© weighted loss et √©quilibrage par batch. L'√©quilibre des donn√©es est CRUCIAL pour un bon apprentissage."
              },
              {
                title: "üîÑ De l'objet au bloc : changement de strat√©gie",
                content: "Approche initiale : extraire chaque objet annot√© individuellement (voiture, pi√©ton, lampadaire). Probl√®me : nombre d'objets insuffisant par classe (certaines classes <10 objets). Solution : Fusionner tous les objets par ville pour recr√©er sc√®ne compl√®te, puis subdiviser en blocs r√©guliers de 10m√ó10m. Avantage : chaque bloc contient plusieurs classes, augmente drastiquement le nombre d'√©chantillons, et correspond mieux √† la r√©alit√© d'utilisation (scanner une zone urbaine)."
              },
              {
                title: "üíª Contraintes mat√©rielles et optimisations",
                content: "GPU GTX 1660 Ti (6GB VRAM) utilis√© : batch_size limit√© √† 8-16 selon architecture, temps par √©poque ~1-2 minutes pour PointNet. Sans GPU : entra√Ænement impossible (√ó100 plus lent). Optimisations n√©cessaires : limitation √† 10000 points max par inf√©rence (subdivision si sc√®ne plus grande), utilisation de PyTorch avec CUDA, impl√©mentation d'early stopping (patience 40) pour √©viter entra√Ænements inutiles."
              },
              {
                title: "üìà Le√ßons d'entra√Ænement sur donn√©es r√©elles",
                content: "Configuration finale test√©e : 100 blocs de Paris+Lille, 300 √©poques, Adam optimizer (lr=0.001), batch size 8. Meilleur r√©sultat : 89% accuracy √† √©poque 98. Observations : La courbe d'accuracy ne converge pas avant 200+ √©poques avec augmentation de donn√©es (bruit, rotation, scale). Plus de donn√©es = convergence plus lente mais meilleure g√©n√©ralisation. Validation set essentiel pour d√©tecter overfitting (s√©paration 70/20/10 train/val/test)."
              }
            ],
            en: [
              {
                title: "üèõÔ∏è PointNet Architecture for Segmentation",
                content: "PointNet processes unordered point clouds via shared MLPs on each point (64‚Üí128‚Üí1024 channels). Global MaxPooling captures global features invariant to permutations. These features are then concatenated with local features of each point for final prediction. Architecture requires exactly 1024 points per input sample, hence importance of resampling."
              },
              {
                title: "üì¶ Urban Data Preparation Challenges",
                content: "Paris-Lille-3D dataset: PLY files contain XYZ coordinates + intensity + label + class. Annotation.txt file describes manually segmented objects. Major issue: extremely unbalanced distribution (only 3 stools in small city = impossible underlearning). Final solution: spatial subdivision into 10m√ó10m blocks covering entire Z height, enabling creation of more training samples."
              },
              {
                title: "‚ö†Ô∏è LiDAR Imbalance Problem",
                content: "Typical distribution in urban LiDAR dataset: Ground (road + sidewalk) = 60-70% of points, Buildings = 15-20%, Vehicles = 5-10%, Urban objects = 2-5%, Vegetation = 3-8%. This overwhelming imbalance causes model to predict majority class even after balancing. Typical result: 97.8% of points predicted as class 9, despite weighted loss and batch balancing. Data balance is CRUCIAL for good learning."
              },
              {
                title: "üîÑ From Object to Block: Strategy Change",
                content: "Initial approach: extract each annotated object individually (car, pedestrian, lamppost). Problem: insufficient number of objects per class (some classes <10 objects). Solution: Merge all objects by city to recreate complete scene, then subdivide into regular 10m√ó10m blocks. Advantage: each block contains multiple classes, drastically increases number of samples, and better matches real-world usage (scanning an urban area)."
              },
              {
                title: "üíª Hardware Constraints and Optimizations",
                content: "GTX 1660 Ti GPU (6GB VRAM) used: batch_size limited to 8-16 depending on architecture, time per epoch ~1-2 minutes for PointNet. Without GPU: training impossible (√ó100 slower). Necessary optimizations: limitation to 10000 points max per inference (subdivision if larger scene), use of PyTorch with CUDA, implementation of early stopping (patience 40) to avoid useless training."
              },
              {
                title: "üìà Training Lessons on Real Data",
                content: "Final configuration tested: 100 blocks from Paris+Lille, 300 epochs, Adam optimizer (lr=0.001), batch size 8. Best result: 89% accuracy at epoch 98. Observations: Accuracy curve doesn't converge before 200+ epochs with data augmentation (noise, rotation, scale). More data = slower convergence but better generalization. Validation set essential to detect overfitting (70/20/10 train/val/test split)."
              }
            ]
          },
          github: "https://github.com/yanimohellebi26/segmentation-semantique"
        },
        {
          name: {
            fr: "Segmentation de Faces de Cube avec PointNet",
            en: "Cube Face Segmentation with PointNet",
          },
          description: {
            fr: "Probl√®me de base pour ma√Ætriser PointNet : classifier les 6 faces d'un cube √† partir d'un nuage de points 3D",
            en: "Basic problem to master PointNet: classify the 6 faces of a cube from a 3D point cloud",
          },
          detailedDescription: {
            fr: "Projet p√©dagogique de segmentation s√©mantique sur g√©om√©trie simple avant d'attaquer les donn√©es urbaines complexes. Objectif : entra√Æner PointNet √† identifier les 6 faces distinctes d'un cube (avant, arri√®re, gauche, droite, haut, bas) dans un nuage de points. G√©n√©ration proc√©durale de 100-1200 cubes avec Blender, 256 points par face (1536 total), variations de rotation et d'√©chelle. Ce projet a permis de comprendre l'architecture PointNet, tester diff√©rents hyperparam√®tres (50-630 √©poques), et identifier les meilleures configurations avant d'appliquer sur donn√©es r√©elles. R√©sultats finaux : 83.71% d'accuracy avec 100 cubes et 300 √©poques, d√©montrant la capacit√© de PointNet sur probl√®mes g√©om√©triques simples.",
            en: "Educational semantic segmentation project on simple geometry before tackling complex urban data. Goal: train PointNet to identify the 6 distinct faces of a cube (front, back, left, right, top, bottom) in a point cloud. Procedural generation of 100-1200 cubes with Blender, 256 points per face (1536 total), rotation and scale variations. This project allowed understanding PointNet architecture, testing different hyperparameters (50-630 epochs), and identifying best configurations before applying on real data. Final results: 83.71% accuracy with 100 cubes and 300 epochs, demonstrating PointNet's capability on simple geometric problems.",
          },
          features: [
            {
              fr: "üé≤ G√©n√©ration de dataset avec Blender : Script Python pour cr√©er cubes param√©triques, 256 points √©chantillonn√©s uniform√©ment par face, Export au format PLY avec √©tiquettes (label 0-5)",
              en: "üé≤ Dataset generation with Blender: Python script to create parametric cubes, 256 points uniformly sampled per face, Export to PLY format with labels (label 0-5)",
            },
            {
              fr: "üîÄ Augmentation de donn√©es avanc√©e : Rotations al√©atoires 3D compl√®tes, Variations d'√©chelle (scale ¬±30%), Bruit gaussien (jittering) pour robustesse, Translation al√©atoire",
              en: "üîÄ Advanced data augmentation: Full 3D random rotations, Scale variations (scale ¬±30%), Gaussian noise (jittering) for robustness, Random translation",
            },
            {
              fr: "üìä Tests d'hyperparam√®tres syst√©matiques : 50 √©poques ‚Üí 51.37% accuracy, 100 √©poques ‚Üí 71.23% accuracy, 150 √©poques ‚Üí 76.66% accuracy (optimal), 200 √©poques ‚Üí d√©gradation (overfitting), 300 √©poques avec 100 cubes ‚Üí 83.71% (meilleur r√©sultat), 630 √©poques avec early stopping ‚Üí arr√™t automatique",
              en: "üìä Systematic hyperparameter testing: 50 epochs ‚Üí 51.37% accuracy, 100 epochs ‚Üí 71.23% accuracy, 150 epochs ‚Üí 76.66% accuracy (optimal), 200 epochs ‚Üí degradation (overfitting), 300 epochs with 100 cubes ‚Üí 83.71% (best result), 630 epochs with early stopping ‚Üí automatic stop",
            },
            {
              fr: "üéØ Architecture optimale identifi√©e : MLP (64‚Üí128‚Üí1024), Batch size: 8, Learning rate: 0.001, Adam optimizer, CrossEntropyLoss non pond√©r√©e (classes √©quilibr√©es)",
              en: "üéØ Optimal architecture identified: MLP (64‚Üí128‚Üí1024), Batch size: 8, Learning rate: 0.001, Adam optimizer, Non-weighted CrossEntropyLoss (balanced classes)",
            },
            {
              fr: "üìà √âvolution du dataset : 10 cubes ‚Üí debugging (baseline), 100 cubes ‚Üí 75.30% (convergence stable), 300 cubes ‚Üí 58.07% (sous-optimis√©, auraient besoin plus d'√©poques), 500 cubes avec bruit ‚Üí convergence plus lente mais meilleure g√©n√©ralisation, 1000 cubes avec 512 points/face ‚Üí accuracy d√©grad√©e (surcompl√©xification)",
              en: "üìà Dataset evolution: 10 cubes ‚Üí debugging (baseline), 100 cubes ‚Üí 75.30% (stable convergence), 300 cubes ‚Üí 58.07% (under-optimized, would need more epochs), 500 cubes with noise ‚Üí slower convergence but better generalization, 1000 cubes with 512 points/face ‚Üí degraded accuracy (over-complexity)",
            },
            {
              fr: "üìâ Visualisations compl√®tes : Courbes loss/accuracy par √©poque, Matrice de confusion 6√ó6, Distribution des pr√©dictions, Nuages de points color√©s par classe vraie/pr√©dite avec Matplotlib",
              en: "üìâ Complete visualizations: Loss/accuracy curves per epoch, 6√ó6 confusion matrix, Prediction distribution, Point clouds colored by true/predicted class with Matplotlib",
            },
          ],
          technologies: [
            "Python",
            "PyTorch",
            "PointNet",
            "Blender",
            "NumPy",
            "Matplotlib",
            "Open3D",
          ],
          results: {
            fr: "üéØ R√©sultats finaux : Meilleure configuration = 100 cubes, 300 √©poques, accuracy maximale 83.71% (√©poque 249). Convergence stable sans overfitting majeur. Temps d'entra√Ænement : ~45 secondes/√©poque sur GTX 1660 Ti. Le√ßons cl√©s : 150 √©poques = sweet spot pour dataset simple, au-del√† de 200 √©poques risque d'overfitting si dataset trop petit. Ajout de bruit ralentit convergence mais am√©liore g√©n√©ralisation. Dataset √©quilibr√© (256 points par face) critique pour bonnes performances. Augmenter densit√© au-del√† de 512 points/face n'am√©liore pas r√©sultats et ralentit entra√Ænement.",
            en: "üéØ Final results: Best configuration = 100 cubes, 300 epochs, maximum accuracy 83.71% (epoch 249). Stable convergence without major overfitting. Training time: ~45 seconds/epoch on GTX 1660 Ti. Key lessons: 150 epochs = sweet spot for simple dataset, beyond 200 epochs risk of overfitting if dataset too small. Adding noise slows convergence but improves generalization. Balanced dataset (256 points per face) critical for good performance. Increasing density beyond 512 points/face doesn't improve results and slows training.",
          },
          keyLearnings: {
            fr: [
              {
                title: "üé≤ G√©n√©ration proc√©durale avec Blender",
                content: "Blender + script Python permet de g√©n√©rer datasets 3D contr√¥l√©s parfaitement. Pour un cube : cr√©er objet primitif, passer en mode √©dition, subdiviser les faces avec bmesh.ops.subdivide_edges pour augmenter la densit√©, r√©cup√©rer vertices et leurs coordonn√©es, associer chaque vertex √† sa face d'origine via face.index. Export PLY : utilise plyfile library, stocke coordonn√©es XYZ + label par point. Alternative sans Blender : g√©n√©ration pure Python mais moins flexible."
              },
              {
                title: "üìä Importance du nombre d'√©poques",
                content: "Tests syst√©matiques montrent : 50 √©poques = sous-apprentissage (51% accuracy), 100 √©poques = apprentissage en cours (71%), 150 √©poques = convergence optimale (76.66%), 200+ √©poques = risque overfitting si dataset petit. Avec 100 cubes et 300 √©poques : pic √† 83.71% puis stabilisation. Ajout bruit/augmentation n√©cessite +100 √©poques pour m√™me convergence car le mod√®le voit des variations continues. Early stopping (patience 40) essentiel pour √©viter entra√Ænements inutiles."
              },
              {
                title: "üîÄ Impact de l'augmentation de donn√©es",
                content: "Sans augmentation : mod√®le m√©morise positions exactes des cubes, √©choue sur nouvelles orientations. Avec rotation 3D al√©atoire : invariance aux orientations, accuracy plus stable. Avec scale ¬±30% : robustesse aux tailles, mais convergence 2√ó plus lente. Avec jittering (bruit gaussien œÉ=0.02) : r√©sistance au bruit de mesure, r√©duit l√©g√®rement overfitting. Combinaison rotation+scale+jitter : meilleure g√©n√©ralisation, mais n√©cessite 500+ √©poques."
              },
              {
                title: "üì¶ Taille optimale du dataset",
                content: "10 cubes : insuffisant, overfitting imm√©diat (<60% accuracy stable). 100 cubes : sweet spot pour debugging, convergence en ~300 √©poques, 83.71% accuracy. 300 cubes : sous-exploit√© avec 300 √©poques (58%), aurait besoin 600+ √©poques. 500-1000 cubes : diminishing returns, temps d'entra√Ænement √ó5 pour gain marginal. Conclusion : Adapter √©poques au nombre d'√©chantillons. Ratio empirique : ~3 √©poques par cube pour convergence."
              },
              {
                title: "üéØ Densit√© de points par face",
                content: "Tests densit√© : 100 points/face (600 total) : apprentissage difficile, geometrie sous-repr√©sent√©e. 256 points/face (1536 total) : OPTIMAL, bon compromis pr√©cision/vitesse. 512 points/face (3072 total) : pas d'am√©lioration accuracy, temps √ó2. Explication : PointNet √©chantillonne √† 1024 en interne via MaxPooling. Au-del√† de ~2000 points, informations redondantes. Pour cube simple, 256 points/face capture suffisamment de g√©om√©trie."
              },
              {
                title: "üí° Pourquoi le cube comme baseline",
                content: "Le cube est id√©al pour comprendre PointNet avant donn√©es r√©elles car : G√©om√©trie simple et sym√©trique, 6 classes √©quilibr√©es naturellement, Pas de complexit√© topologique, Rapide √† g√©n√©rer et entra√Æner (~20 min pour 300 √©poques), Diagnostics faciles : si accuracy <70% ‚Üí probl√®me architecture/hyperparam√®tres, si accuracy >90% ‚Üí augmentation insuffisante (m√©morisation). Permet tester syst√©matiquement impact de chaque hyperparam√®tre."
              }
            ],
            en: [
              {
                title: "üé≤ Procedural Generation with Blender",
                content: "Blender + Python script allows generating perfectly controlled 3D datasets. For a cube: create primitive object, switch to edit mode, subdivide faces with bmesh.ops.subdivide_edges to increase density, retrieve vertices and their coordinates, associate each vertex to its original face via face.index. PLY export: uses plyfile library, stores XYZ coordinates + label per point. Alternative without Blender: pure Python generation but less flexible."
              },
              {
                title: "üìä Importance of Number of Epochs",
                content: "Systematic tests show: 50 epochs = underlearning (51% accuracy), 100 epochs = learning in progress (71%), 150 epochs = optimal convergence (76.66%), 200+ epochs = overfitting risk if small dataset. With 100 cubes and 300 epochs: peak at 83.71% then stabilization. Adding noise/augmentation requires +100 epochs for same convergence as model sees continuous variations. Early stopping (patience 40) essential to avoid useless training."
              },
              {
                title: "üîÄ Impact of Data Augmentation",
                content: "Without augmentation: model memorizes exact cube positions, fails on new orientations. With random 3D rotation: orientation invariance, more stable accuracy. With scale ¬±30%: size robustness, but 2√ó slower convergence. With jittering (Gaussian noise œÉ=0.02): measurement noise resistance, slightly reduces overfitting. Combination rotation+scale+jitter: best generalization, but requires 500+ epochs."
              },
              {
                title: "üì¶ Optimal Dataset Size",
                content: "10 cubes: insufficient, immediate overfitting (<60% stable accuracy). 100 cubes: sweet spot for debugging, convergence in ~300 epochs, 83.71% accuracy. 300 cubes: underexploited with 300 epochs (58%), would need 600+ epochs. 500-1000 cubes: diminishing returns, 5√ó training time for marginal gain. Conclusion: Adapt epochs to number of samples. Empirical ratio: ~3 epochs per cube for convergence."
              },
              {
                title: "üéØ Point Density per Face",
                content: "Density tests: 100 points/face (600 total): difficult learning, underrepresented geometry. 256 points/face (1536 total): OPTIMAL, good accuracy/speed compromise. 512 points/face (3072 total): no accuracy improvement, 2√ó time. Explanation: PointNet samples at 1024 internally via MaxPooling. Beyond ~2000 points, redundant information. For simple cube, 256 points/face captures sufficient geometry."
              },
              {
                title: "üí° Why Cube as Baseline",
                content: "Cube is ideal for understanding PointNet before real data because: Simple and symmetric geometry, 6 naturally balanced classes, No topological complexity, Fast to generate and train (~20 min for 300 epochs), Easy diagnostics: if accuracy <70% ‚Üí architecture/hyperparameter problem, if accuracy >90% ‚Üí insufficient augmentation (memorization). Allows systematically testing impact of each hyperparameter."
              }
            ]
          },
          github: "https://github.com/yanimohellebi26/segmentation-face-cube"
        },
        {
          name: {
            fr: "Exploration de KPConv pour Segmentation 3D",
            en: "KPConv Exploration for 3D Segmentation",
          },
          description: {
            fr: "Tentative d'impl√©mentation de Kernel Point Convolution (KPConv) pour am√©liorer les r√©sultats sur cubes, avec analyse des limitations",
            en: "Implementation attempt of Kernel Point Convolution (KPConv) to improve cube results, with limitation analysis",
          },
          detailedDescription: {
            fr: "Projet exploratoire pour tester KPConv comme alternative √† PointNet sur le probl√®me de segmentation de cubes. KPConv (Thomas et al., 2019) est une architecture plus sophistiqu√©e utilisant des convolutions sur points noyaux dans l'espace 3D, avec recherche de voisinage local. L'impl√©mentation custom en PyTorch incluait des KPConvLayer avec rayon fixe et kernel points fig√©s, organis√©s en blocs avec BatchNorm et ReLU (architecture 1‚Üí16‚Üí32‚Üí64‚Üí128‚Üí6 classes). Tests avec 1200 cubes, 300 √©poques, learning rate 0.001-0.003, et diff√©rents schedulers (ReduceLROnPlateau, CosineAnnealingWarmRestarts). R√©sultat : performances d√©cevantes (22.6% accuracy) et temps d'entra√Ænement √ó30 plus long (1 min/√©poque vs 2 sec pour PointNet). Conclusion : KPConv inadapt√© pour g√©om√©tries simples, requiert plus de features en entr√©e et fonctionne mieux sur donn√©es spatiales complexes.",
            en: "Exploratory project to test KPConv as alternative to PointNet on cube segmentation problem. KPConv (Thomas et al., 2019) is a more sophisticated architecture using convolutions on kernel points in 3D space, with local neighborhood search. Custom PyTorch implementation included KPConvLayer with fixed radius and frozen kernel points, organized in blocks with BatchNorm and ReLU (architecture 1‚Üí16‚Üí32‚Üí64‚Üí128‚Üí6 classes). Tests with 1200 cubes, 300 epochs, learning rate 0.001-0.003, and different schedulers (ReduceLROnPlateau, CosineAnnealingWarmRestarts). Result: disappointing performance (22.6% accuracy) and √ó30 longer training time (1 min/epoch vs 2 sec for PointNet). Conclusion: KPConv unsuitable for simple geometries, requires more input features and works better on complex spatial data.",
          },
          features: [
            {
              fr: "üèóÔ∏è Impl√©mentation KPConv from scratch : KPConvLayer avec kernel points fixes (15 points noyaux), recherche de voisinage par rayon, pond√©ration par distance gaussienne, KPConvBlock = KPConv + BatchNorm + ReLU",
              en: "üèóÔ∏è KPConv implementation from scratch: KPConvLayer with fixed kernel points (15 kernel points), radius neighborhood search, Gaussian distance weighting, KPConvBlock = KPConv + BatchNorm + ReLU",
            },
            {
              fr: "üìä Tests architectures multiples : Baseline (1‚Üí32‚Üí64‚Üí128‚Üí6), Large (1‚Üí16‚Üí32‚Üí64‚Üí128‚Üí6), Diff√©rents rayons de voisinage test√©s, Avec/sans deformable kernel points",
              en: "üìä Multiple architecture tests: Baseline (1‚Üí32‚Üí64‚Üí128‚Üí6), Large (1‚Üí16‚Üí32‚Üí64‚Üí128‚Üí6), Different neighborhood radii tested, With/without deformable kernel points",
            },
            {
              fr: "üîß Optimisations tent√©es : Learning rates vari√©s (0.001, 0.003), Schedulers multiples (ReduceLROnPlateau, CosineAnnealingWarmRestarts), Batch sizes ajust√©s (4, 8, 16), Early stopping (patience 30-40)",
              en: "üîß Optimization attempts: Various learning rates (0.001, 0.003), Multiple schedulers (ReduceLROnPlateau, CosineAnnealingWarmRestarts), Adjusted batch sizes (4, 8, 16), Early stopping (patience 30-40)",
            },
            {
              fr: "‚è±Ô∏è Analyse performance : Temps d'entra√Ænement : ~1 min/√©poque (vs 2 sec pour PointNet), Arr√™t pr√©matur√© : √©poque 20-30 avec early stopping, Memory footprint : √ó2 plus √©lev√©, Convergence tr√®s lente",
              en: "‚è±Ô∏è Performance analysis: Training time: ~1 min/epoch (vs 2 sec for PointNet), Premature stopping: epoch 20-30 with early stopping, Memory footprint: √ó2 higher, Very slow convergence",
            },
            {
              fr: "üîç Test de validation : MLP simple sur un cube individuel ‚Üí 94% accuracy, Confirme que le probl√®me est l'architecture KPConv, Donn√©es cubiques trop simples pour KPConv",
              en: "üîç Validation test: Simple MLP on individual cube ‚Üí 94% accuracy, Confirms problem is KPConv architecture, Cube data too simple for KPConv",
            },
          ],
          technologies: [
            "Python",
            "PyTorch",
            "KPConv",
            "NumPy",
            "Matplotlib",
          ],
          results: {
            fr: "üéØ R√©sultats finaux : Meilleure accuracy obtenue : 22.6% (√©poque 20), bien inf√©rieure √† PointNet (83.71%). Arr√™t automatique apr√®s 30 √©poques sans am√©lioration. Temps total : 0.36 heures pour entra√Ænement incomplet. Analyse des √©checs : KPConv n√©cessite features riches en entr√©e (normales, couleurs, intensit√©s) et non juste XYZ, architecture trop complexe pour g√©om√©trie simple du cube, recherche de voisinage locale inefficace sur objets uniformes. Validation du probl√®me : test MLP simple sur cube ‚Üí 94% accuracy, confirmant que les donn√©es sont bonnes. Conclusion : KPConv orient√© pour segmentation de sc√®nes complexes (mobilier, int√©rieurs), pas pour classification g√©om√©trique simple. PointNet reste meilleur choix pour ce type de probl√®me.",
            en: "üéØ Final results: Best accuracy obtained: 22.6% (epoch 20), well below PointNet (83.71%). Automatic stop after 30 epochs without improvement. Total time: 0.36 hours for incomplete training. Failure analysis: KPConv requires rich input features (normals, colors, intensities) not just XYZ, architecture too complex for simple cube geometry, local neighborhood search inefficient on uniform objects. Problem validation: simple MLP test on cube ‚Üí 94% accuracy, confirming data is good. Conclusion: KPConv oriented for complex scene segmentation (furniture, interiors), not for simple geometric classification. PointNet remains better choice for this type of problem.",
          },
          keyLearnings: {
            fr: [
              {
                title: "üèóÔ∏è Architecture KPConv expliqu√©e",
                content: "KPConv place un ensemble fixe de kernel points (ex: 15 points) dans l'espace 3D autour de chaque point d'entr√©e. Pour chaque point : recherche des voisins dans un rayon donn√© (ex: 0.2m), les features des voisins sont pond√©r√©es selon leur distance aux kernel points (pond√©ration gaussienne), agr√©gation via convolution avec poids apprenables sur les kernel points. Architecture type : s√©quence de KPConvBlock avec subsampling progressif (similar √† UNet). Plus complexe que PointNet car n√©cessite gestion explicite du voisinage."
              },
              {
                title: "‚ö†Ô∏è Pourquoi KPConv a √©chou√© sur les cubes",
                content: "Cube = objet trop simple et sym√©trique. KPConv excelle sur g√©om√©tries complexes avec variations locales fortes (chaises, tables, sc√®nes int√©rieures). Sur cube : voisinages tr√®s uniformes, peu de caract√©ristiques locales discriminantes, les 6 faces sont g√©om√©triquement identiques (seule orientation diff√®re). KPConv ne peut pas exploiter sa puissance sur donn√©es aussi r√©guli√®res. Features XYZ seules insuffisantes - KPConv con√ßu pour features riches (normales, couleurs, courbures)."
              },
              {
                title: "‚è±Ô∏è Co√ªt computationnel de KPConv",
                content: "Recherche de voisinage : O(n log n) via KDTree ou ball query, tr√®s co√ªteux. PointNet : O(n) simple MLP par point, pas de recherche. Sur GTX 1660 Ti : KPConv = 1 min/√©poque pour 8 cubes, PointNet = 2 sec/√©poque. Facteur √ó30 plus lent. Memory footprint √ó2-3 plus √©lev√© (stockage des indices de voisinage). Pour dataset 1200 cubes, KPConv n√©cessiterait ~20 heures pour 300 √©poques vs ~40 minutes pour PointNet."
              },
              {
                title: "üîç Validation par MLP simple",
                content: "Test critique effectu√© : MLP 3 couches (XYZ ‚Üí 128 ‚Üí 64 ‚Üí 6 classes) sur un seul cube. R√©sultat : 94% accuracy en quelques √©poques. Prouve que : donn√©es sont correctes et learnable, probl√®me vient de l'architecture KPConv inadapt√©e. Cette validation est essentielle quand une architecture complexe √©choue - toujours tester avec baseline simple pour isoler le probl√®me."
              },
              {
                title: "üéØ Quand utiliser KPConv vs PointNet",
                content: "PointNet : objets simples ou classification globale, dataset mod√©r√© (<10k √©chantillons), features limit√©es (XYZ, peut-√™tre normales), besoin de vitesse d'entra√Ænement. KPConv : sc√®nes complexes avec d√©tails locaux, dataset large (>50k), features riches disponibles, segmentation fine n√©cessaire. Pour urban segmentation : KPConv serait mieux SI on avait features (intensit√© LiDAR, normales, RGB). Pour cubes ou formes g√©om√©triques simples : PointNet largement suffisant."
              },
              {
                title: "üí° Le√ßons d'architecture deep learning",
                content: "Plus complexe ‚â† meilleur. Occam's Razor s'applique : choisir l'architecture la plus simple qui r√©sout le probl√®me. KPConv est state-of-the-art pour segmentation 3D complexe, mais overkill pour g√©om√©tries simples. Co√ªt computationnel doit √™tre justifi√© par gain de performance. Ici : KPConv √ó30 plus lent et -60% accuracy ‚Üí clairement inadapt√©. Toujours benchmarker avec baseline simple (MLP, PointNet) avant d'investir dans architectures sophistiqu√©es."
              }
            ],
            en: [
              {
                title: "üèóÔ∏è KPConv Architecture Explained",
                content: "KPConv places a fixed set of kernel points (e.g.: 15 points) in 3D space around each input point. For each point: search for neighbors within given radius (e.g.: 0.2m), neighbor features are weighted according to distance to kernel points (Gaussian weighting), aggregation via convolution with learnable weights on kernel points. Typical architecture: sequence of KPConvBlock with progressive subsampling (similar to UNet). More complex than PointNet as requires explicit neighborhood management."
              },
              {
                title: "‚ö†Ô∏è Why KPConv Failed on Cubes",
                content: "Cube = too simple and symmetric object. KPConv excels on complex geometries with strong local variations (chairs, tables, interior scenes). On cube: very uniform neighborhoods, few discriminative local features, 6 faces are geometrically identical (only orientation differs). KPConv cannot exploit its power on such regular data. XYZ features alone insufficient - KPConv designed for rich features (normals, colors, curvatures)."
              },
              {
                title: "‚è±Ô∏è Computational Cost of KPConv",
                content: "Neighborhood search: O(n log n) via KDTree or ball query, very expensive. PointNet: O(n) simple MLP per point, no search. On GTX 1660 Ti: KPConv = 1 min/epoch for 8 cubes, PointNet = 2 sec/epoch. Factor √ó30 slower. Memory footprint √ó2-3 higher (storage of neighborhood indices). For 1200 cube dataset, KPConv would require ~20 hours for 300 epochs vs ~40 minutes for PointNet."
              },
              {
                title: "üîç Validation with Simple MLP",
                content: "Critical test performed: 3-layer MLP (XYZ ‚Üí 128 ‚Üí 64 ‚Üí 6 classes) on single cube. Result: 94% accuracy in few epochs. Proves that: data is correct and learnable, problem comes from KPConv architecture being unsuitable. This validation is essential when complex architecture fails - always test with simple baseline to isolate problem."
              },
              {
                title: "üéØ When to Use KPConv vs PointNet",
                content: "PointNet: simple objects or global classification, moderate dataset (<10k samples), limited features (XYZ, maybe normals), need for training speed. KPConv: complex scenes with local details, large dataset (>50k), rich features available, fine segmentation needed. For urban segmentation: KPConv would be better IF we had features (LiDAR intensity, normals, RGB). For cubes or simple geometric shapes: PointNet largely sufficient."
              },
              {
                title: "üí° Deep Learning Architecture Lessons",
                content: "More complex ‚â† better. Occam's Razor applies: choose simplest architecture that solves problem. KPConv is state-of-the-art for complex 3D segmentation, but overkill for simple geometries. Computational cost must be justified by performance gain. Here: KPConv √ó30 slower and -60% accuracy ‚Üí clearly unsuitable. Always benchmark with simple baseline (MLP, PointNet) before investing in sophisticated architectures."
              }
            ]
          },
          github: "https://github.com/yanimohellebi26/reconnaissance_maison-nuage-de-points"
        },
        {
          name: {
            fr: "Reconnaissance d'√âl√©ments Architecturaux (Murs et Ouvertures)",
            en: "Architectural Element Recognition (Walls and Openings)",
          },
          description: {
            fr: "Segmentation de maisons 3D g√©n√©r√©es param√©triquement pour distinguer murs ext√©rieurs et ouvertures (portes/fen√™tres)",
            en: "Segmentation of parametrically generated 3D houses to distinguish exterior walls and openings (doors/windows)",
          },
          detailedDescription: {
            fr: "Projet de segmentation s√©mantique d'√©l√©ments architecturaux simples, utilisant des mod√®les 3D de maisons g√©n√©r√©s proc√©duralement avec Blender. Objectif : entra√Æner PointNet avec T-Net (transformation spatiale) √† classifier deux cat√©gories : murs ext√©rieurs (classe 0) et ouvertures - portes et fen√™tres (classe 1). G√©n√©ration param√©trique de maisons vari√©es : rectangles simples, forme en L, carr√©es compactes, avec 1-4 ouvertures par maison (portes 1.8-2.2m √ó 0.6-1.2m, fen√™tres 0.8-1.5m carr√©es/rectangulaires). Export en nuages de points XYZ avec densit√© √©lev√©e (70% points sur bords, 30% sur faces). Split train/val/test avec distribution √©quilibr√©e. Meilleurs r√©sultats : 88.96% validation accuracy, 82.99% test accuracy, entra√Ænement stable en ~300 √©poques. Ce projet d√©montre l'efficacit√© de PointNet sur probl√®mes architecturaux binaires avec donn√©es bien √©quilibr√©es.",
            en: "Semantic segmentation project of simple architectural elements, using procedurally generated 3D house models with Blender. Goal: train PointNet with T-Net (spatial transformation) to classify two categories: exterior walls (class 0) and openings - doors and windows (class 1). Parametric generation of varied houses: simple rectangles, L-shaped, compact squares, with 1-4 openings per house (doors 1.8-2.2m √ó 0.6-1.2m, windows 0.8-1.5m square/rectangular). Export to XYZ point clouds with high density (70% points on edges, 30% on faces). Train/val/test split with balanced distribution. Best results: 88.96% validation accuracy, 82.99% test accuracy, stable training in ~300 epochs. This project demonstrates PointNet's effectiveness on binary architectural problems with well-balanced data.",
          },
          features: [
            {
              fr: "üè† G√©n√©ration param√©trique de maisons : 4 types de plans (rectangle, L, carr√©, couloir), Dimensions variables (largeur/profondeur 4-12m, hauteur 2.5-3.5m), √âpaisseur murs al√©atoire (0.15-0.30m), G√©n√©ration pure Python (pas de Blender pour dataset final)",
              en: "üè† Parametric house generation: 4 floor plan types (rectangle, L, square, corridor), Variable dimensions (width/depth 4-12m, height 2.5-3.5m), Random wall thickness (0.15-0.30m), Pure Python generation (no Blender for final dataset)",
            },
            {
              fr: "üö™ Ouvertures r√©alistes : Portes : hauteur 1.8-2.2m, largeur 0.6-1.2m, position al√©atoire sur mur, Fen√™tres : carr√©es ou rectangulaires, hauteur base 0.5-1.5m, largeur 0.8-1.5m, 1-4 ouvertures par maison",
              en: "üö™ Realistic openings: Doors: height 1.8-2.2m, width 0.6-1.2m, random wall position, Windows: square or rectangular, base height 0.5-1.5m, width 0.8-1.5m, 1-4 openings per house",
            },
            {
              fr: "üéØ Architecture PointNet avec T-Net : T-Net pour normalisation spatiale (g√©n√®re matrice 3√ó3), MLP encodeur (64‚Üí128‚Üí1024) avec BatchNorm, MaxPooling global, MLP d√©codeur (1024‚Üí512‚Üí256‚Üí2 classes), Softmax final pour pr√©diction",
              en: "üéØ PointNet architecture with T-Net: T-Net for spatial normalization (generates 3√ó3 matrix), MLP encoder (64‚Üí128‚Üí1024) with BatchNorm, Global MaxPooling, MLP decoder (1024‚Üí512‚Üí256‚Üí2 classes), Final Softmax for prediction",
            },
            {
              fr: "üìä Strat√©gie d'√©chantillonnage optimis√©e : Densit√© diff√©rentielle : 70% points sur bords (d√©tails g√©om√©triques), 30% points sur faces (remplissage), Points uniform√©ment r√©partis par √©l√©ment, Export format XYZ avec label par point",
              en: "üìä Optimized sampling strategy: Differential density: 70% points on edges (geometric details), 30% points on faces (filling), Uniformly distributed points per element, XYZ format export with label per point",
            },
            {
              fr: "üîÑ Augmentation et split : Rotations al√©atoires 3D, Variations d'√©chelle (¬±30%), Miroir X ou Y, Split : 70% train, 20% val, 10% test, Distribution √©quilibr√©e entre classes",
              en: "üîÑ Augmentation and split: Random 3D rotations, Scale variations (¬±30%), X or Y mirroring, Split: 70% train, 20% val, 10% test, Balanced distribution between classes",
            },
            {
              fr: "üìà Configuration optimale : Batch size: 8, Learning rate: 0.001, Optimizer: Adam, Loss: CrossEntropyLoss non pond√©r√©e, ~300 √©poques pour convergence, Vitesse: 27-44 it/s (sec/√©poque)",
              en: "üìà Optimal configuration: Batch size: 8, Learning rate: 0.001, Optimizer: Adam, Loss: non-weighted CrossEntropyLoss, ~300 epochs for convergence, Speed: 27-44 it/s (sec/epoch)",
            },
          ],
          technologies: [
            "Python",
            "PyTorch",
            "PointNet",
            "T-Net",
            "NumPy",
            "Matplotlib",
            "Blender (prototypage initial)",
          ],
          results: {
            fr: "üéØ R√©sultats finaux : Meilleure Validation Accuracy : 88.96%, Test Accuracy Finale : 82.99%, Convergence stable sans overfitting majeur. Temps d'entra√Ænement par √©poque : 27-44 secondes sur GTX 1660 Ti. Matrices de confusion excellentes : peu de confusion entre murs et ouvertures. Visualisations 3D montrent segmentation pr√©cise des ouvertures. Facteurs de succ√®s : classes bien √©quilibr√©es (contrairement au dataset urbain), probl√®me binaire plus simple que 6-10 classes, densit√© de points √©lev√©e sur zones critiques (bords d'ouvertures), augmentation de donn√©es efficace. Comparaison : ce projet atteint ~83% test accuracy l√† o√π le dataset urbain plafonnait √† 89% train avec d√©s√©quilibre extr√™me.",
            en: "üéØ Final results: Best Validation Accuracy: 88.96%, Final Test Accuracy: 82.99%, Stable convergence without major overfitting. Training time per epoch: 27-44 seconds on GTX 1660 Ti. Excellent confusion matrices: little confusion between walls and openings. 3D visualizations show precise opening segmentation. Success factors: well-balanced classes (unlike urban dataset), simpler binary problem than 6-10 classes, high point density on critical areas (opening edges), effective data augmentation. Comparison: this project achieves ~83% test accuracy where urban dataset plateaued at 89% train with extreme imbalance.",
          },
          keyLearnings: {
            fr: [
              {
                title: "üèóÔ∏è T-Net : normalisation spatiale apprise",
                content: "T-Net est un mini-r√©seau qui pr√©dit une matrice de transformation 3√ó3 pour normaliser l'orientation et la position de chaque nuage de points avant traitement. Architecture T-Net : m√™mes couches que PointNet (Conv1D 64‚Üí128‚Üí1024), MLP pour g√©n√©rer 9 param√®tres, Reshape en matrice 3√ó3, Addition avec matrice identit√© pour stabilit√©. Avantage : invariance compl√®te aux rotations 3D arbitraires, pas besoin d'aligner manuellement les donn√©es. Appliqu√© au d√©but du r√©seau, am√©liore robustesse. Co√ªt computationnel n√©gligeable (+5% temps d'entra√Ænement)."
              },
              {
                title: "üè† G√©n√©ration proc√©durale d'architectures",
                content: "G√©n√©ration pure Python (sans Blender pour production) : d√©finir plans de sol comme s√©quences de segments (rectangles, L-shapes), cr√©er murs comme extrusions verticales de segments, d√©couper ouvertures en calculant intersections g√©om√©triques. Alternative initialement tent√©e : Blender avec d√©coupe bool√©enne (cr√©er cube, soustraire ouvertures), mais trop complexe √† automatiser et lent. Solution retenue : repr√©senter ouvertures comme objets s√©par√©s avec densit√© de points diff√©rente. Portes/fen√™tres = rectangles 3D positionn√©s sur faces de murs."
              },
              {
                title: "üìä Importance de la densit√© diff√©rentielle",
                content: "Premi√®re tentative : densit√© uniforme ‚Üí mod√®le confond bords et int√©rieurs des ouvertures. Solution : 70% points sur bords (ar√™tes de fen√™tres/portes), 30% sur faces. Justification : bords contiennent l'information g√©om√©trique critique (transitions mur‚Üíouverture). Points de face servent surtout √† 'remplir' l'espace. R√©sultat : am√©lioration +15% accuracy avec m√™me nombre total de points. Alternative non test√©e : ajouter features normales de surface (mais PointNet standard n'utilise que XYZ)."
              },
              {
                title: "‚öñÔ∏è √âquilibre de classes = crucial",
                content: "Contrairement au dataset urbain (sol 70%, autres <10%), ici classes √©quilibr√©es naturellement : murs ~55-60% points, ouvertures ~40-45% points. R√©sultat : pas besoin de weighted loss, convergence plus rapide, accuracy finale meilleure. Le√ßon principale : pour segmentation, l'√©quilibre des donn√©es est PLUS important que la quantit√©. Mieux vaut 1000 √©chantillons √©quilibr√©s que 10000 d√©s√©quilibr√©s. Sur ce projet, 300 maisons avec bon √©quilibre > 1200 cubes urbains d√©s√©quilibr√©s."
              },
              {
                title: "üéØ Simplification progressive vers binaire",
                content: "√âvolution du probl√®me : Tentative initiale : 3 classes (murs, portes, fen√™tres) ‚Üí confusion portes/fen√™tres. R√©duction : 2 classes (murs, ouvertures) ‚Üí bien meilleure performance. Justification : portes et fen√™tres ont g√©om√©tries tr√®s similaires (rectangles), distinction surtout par taille/position (features non disponibles dans XYZ seul). Pour applications r√©elles : d√©tecter pr√©sence d'ouverture souvent suffisant, distinction porte/fen√™tre peut se faire par post-processing (r√®gles sur dimensions)."
              },
              {
                title: "üí° Du cube synth√©tique √† l'architecture",
                content: "Progression p√©dagogique efficace : Cube (6 faces) ‚Üí comprendre PointNet, Maisons (2 classes) ‚Üí application architecturale simple, Donn√©es urbaines (10 classes) ‚Üí probl√®me r√©el complexe. Maisons = sweet spot : assez complexe pour √™tre int√©ressant, assez simple pour bien fonctionner, plus proche r√©alit√© que cubes, temps d'entra√Ænement raisonnable. Ce projet valide que PointNet est adapt√© √† la segmentation architecturale avec donn√©es bien pr√©par√©es."
              }
            ],
            en: [
              {
                title: "üèóÔ∏è T-Net: Learned Spatial Normalization",
                content: "T-Net is a mini-network that predicts a 3√ó3 transformation matrix to normalize orientation and position of each point cloud before processing. T-Net architecture: same layers as PointNet (Conv1D 64‚Üí128‚Üí1024), MLP to generate 9 parameters, Reshape to 3√ó3 matrix, Addition with identity matrix for stability. Advantage: complete invariance to arbitrary 3D rotations, no need to manually align data. Applied at network start, improves robustness. Negligible computational cost (+5% training time)."
              },
              {
                title: "üè† Procedural Architecture Generation",
                content: "Pure Python generation (no Blender for production): define floor plans as sequences of segments (rectangles, L-shapes), create walls as vertical extrusions of segments, cut openings by calculating geometric intersections. Initially attempted alternative: Blender with boolean cutting (create cube, subtract openings), but too complex to automate and slow. Retained solution: represent openings as separate objects with different point density. Doors/windows = 3D rectangles positioned on wall faces."
              },
              {
                title: "üìä Importance of Differential Density",
                content: "First attempt: uniform density ‚Üí model confuses edges and interiors of openings. Solution: 70% points on edges (window/door edges), 30% on faces. Justification: edges contain critical geometric information (wall‚Üíopening transitions). Face points mainly serve to 'fill' space. Result: +15% accuracy improvement with same total number of points. Untested alternative: add surface normal features (but standard PointNet only uses XYZ)."
              },
              {
                title: "‚öñÔ∏è Class Balance = Crucial",
                content: "Unlike urban dataset (ground 70%, others <10%), here naturally balanced classes: walls ~55-60% points, openings ~40-45% points. Result: no need for weighted loss, faster convergence, better final accuracy. Main lesson: for segmentation, data balance is MORE important than quantity. Better to have 1000 balanced samples than 10000 unbalanced. In this project, 300 houses with good balance > 1200 unbalanced urban cubes."
              },
              {
                title: "üéØ Progressive Simplification to Binary",
                content: "Problem evolution: Initial attempt: 3 classes (walls, doors, windows) ‚Üí door/window confusion. Reduction: 2 classes (walls, openings) ‚Üí much better performance. Justification: doors and windows have very similar geometries (rectangles), distinction mainly by size/position (features not available in XYZ alone). For real applications: detecting opening presence often sufficient, door/window distinction can be done by post-processing (rules on dimensions)."
              },
              {
                title: "üí° From Synthetic Cube to Architecture",
                content: "Effective pedagogical progression: Cube (6 faces) ‚Üí understand PointNet, Houses (2 classes) ‚Üí simple architectural application, Urban data (10 classes) ‚Üí complex real problem. Houses = sweet spot: complex enough to be interesting, simple enough to work well, closer to reality than cubes, reasonable training time. This project validates that PointNet is suitable for architectural segmentation with well-prepared data."
              }
            ]
          },
          github: "https://github.com/yanimohellebi26/reconnaissance_maison-nuage-de-points"
        }
      ],
      technologies: [
        "Python",
        "PyTorch",
        "PointNet",
        "KPConv",
        "NumPy",
        "Pandas",
        "Plyfile",
        "H5py",
        "Open3D",
        "Matplotlib",
        "Seaborn",
        "Blender",
        "CUDA",
      ],
    },
  ];

  return (
    <div className="space-y-8">
      <h2 className="text-center text-2xl font-bold text-brand-accent sm:text-3xl">
        {language === "fr"
          ? "Exp√©rience Professionnelle"
          : "Professional Experience"}
      </h2>

      <div className="relative space-y-8">
        {/* Timeline line */}
        <div className="absolute left-8 top-0 h-full w-0.5 bg-gradient-to-b from-brand-accent via-brand-accent/50 to-transparent" />

        {experiences.map((exp, index) => (
          <div key={exp.id} className="relative pl-20">
            {/* Timeline dot */}
            <div
              className={`absolute left-6 top-6 h-5 w-5 rounded-full border-4 ${
                exp.current
                  ? "animate-pulse border-brand-accent bg-brand-accent"
                  : "border-brand-accent/50 bg-brand-bg"
              }`}
            />

            {/* Experience card */}
            <div className="group rounded-2xl border border-white/10 bg-white/[0.04] p-6 backdrop-blur-sm transition-all hover:-translate-y-1 hover:border-brand-accent/40 hover:bg-white/[0.08] hover:shadow-xl">
              {/* Current badge */}
              {exp.current && (
                <div className="mb-4 inline-flex items-center gap-2 rounded-full bg-brand-accent/20 px-3 py-1 text-xs font-semibold text-brand-accent">
                  <span className="h-2 w-2 animate-pulse rounded-full bg-brand-accent" />
                  {language === "fr" ? "En cours" : "Current"}
                </div>
              )}

              {/* Role and Company */}
              <div className="mb-4">
                <h3 className="mb-2 text-xl font-bold text-brand-text">
                  {language === "fr" ? exp.role.fr : exp.role.en}
                </h3>
                <p className="flex items-center gap-2 text-lg font-semibold text-brand-accent">
                  <FaBriefcase className="text-base" />
                  {typeof exp.company === "object"
                    ? language === "fr"
                      ? exp.company.fr
                      : exp.company.en
                    : exp.company}
                </p>
              </div>

              {/* Location and Period */}
              <div className="mb-4 flex flex-wrap gap-4 text-sm text-brand-muted">
                <div className="flex items-center gap-2">
                  <MdLocationOn className="text-brand-accent" />
                  {exp.location}
                </div>
                <div className="flex items-center gap-2">
                  <MdDateRange className="text-brand-accent" />
                  {language === "fr" ? exp.period.fr : exp.period.en}
                </div>
              </div>

              {/* Description */}
              <p className="mb-4 text-brand-text/80">
                {language === "fr" ? exp.description.fr : exp.description.en}
              </p>

              {/* Research Projects (for internship) */}
              {exp.projects && (
                <div className="mb-4 space-y-3">
                  <h4 className="font-semibold text-brand-accent">
                    {language === "fr"
                      ? "Projets de Recherche :"
                      : "Research Projects:"}
                  </h4>
                  {exp.projects.map((project, idx) => (
                    <div
                      key={idx}
                      className="cursor-pointer rounded-lg border border-white/5 bg-white/[0.02] p-4 transition-all hover:border-brand-accent/30 hover:bg-white/[0.05] hover:shadow-lg"
                      onClick={() => setSelectedProject(project)}
                    >
                      <div className="mb-2 flex items-start justify-between gap-4">
                        <h5 className="font-semibold text-brand-text">
                          {language === "fr"
                            ? project.name.fr
                            : project.name.en}
                        </h5>
                        <a
                          href={project.github}
                          target="_blank"
                          rel="noopener noreferrer"
                          className="flex-shrink-0 text-brand-accent transition-colors hover:text-brand-accent/80"
                          aria-label="GitHub repository"
                          onClick={(e) => e.stopPropagation()}
                        >
                          <FaGithub className="text-xl" />
                        </a>
                      </div>
                      <p className="text-sm text-brand-text/70">
                        {language === "fr"
                          ? project.description.fr
                          : project.description.en}
                      </p>
                      <p className="mt-2 text-xs font-medium text-brand-accent">
                        {language === "fr"
                          ? "Cliquez pour plus de d√©tails ‚Üí"
                          : "Click for more details ‚Üí"}
                      </p>
                    </div>
                  ))}
                </div>
              )}

              {/* Technologies */}
              <div>
                <h4 className="mb-3 text-sm font-semibold uppercase tracking-wider text-brand-muted">
                  {language === "fr" ? "Technologies" : "Technologies"}
                </h4>
                <div className="flex flex-wrap gap-2">
                  {exp.technologies.map((tech, idx) => (
                    <span
                      key={idx}
                      className="rounded-lg border border-brand-accent/20 bg-brand-accent/10 px-3 py-1 text-xs font-medium text-brand-accent transition-colors hover:border-brand-accent/40 hover:bg-brand-accent/20"
                    >
                      {tech}
                    </span>
                  ))}
                </div>
              </div>
            </div>
          </div>
          ))}
      </div>

      {/* Project Modal */}
      {selectedProject && (
        <ProjectModal
          project={selectedProject}
          onClose={() => setSelectedProject(null)}
        />
      )}
    </div>
  );
}

export default Experience;